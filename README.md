# Mini Transformer

## Introduction

This repository references several well-known deep learning/large model repositories such as "Dive into Deep Learning" and "LLMs-from-scratch", and follows the design pattern of the transformers library, aimed at learning the underlying principles of deep learning/large models and common techniques like inference and training.

At the same time, this repository is also a well-organized Python project managed by uv, which can be used to quickly build environments and run with uv.

**Note:** This repository is still under development and may not be fully functional. Although the repository imitates the organization of the transformers library, it only implements the most basic functions, and its adaptability and compatibility are far inferior to the corresponding functions in transformers.

## Reference List

- [Dive into Deep Learning](https://github.com/d2l-ai/d2l-en)
- [LLMs-from-scratch](https://github.com/rasbt/LLMs-from-scratch)
- [transformers](https://github.com/huggingface/transformers)

